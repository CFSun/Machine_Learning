{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "---\n",
    "\n",
    "**In logistic regression the response variabl y is categrical, in constrast to linear regression, which has continuous response variable y. **\n",
    "\n",
    "\\begin{equation}\n",
    " y = b + wx \n",
    "\\end{equation}\n",
    "\n",
    "**Where A is the intercept and B is the slope. In case Y is binary, we use 1/0 to represent them. **\n",
    "    \n",
    "    This is a classification problems, which can be for:  \n",
    "        - Spam email(yes/no), \n",
    "        - Cancer(Yes/No), \n",
    "\t\t- Buy product(yes/no)\n",
    "\t\t- College admission(Yes/no)\n",
    "        ....\n",
    "        \n",
    "** The following graph shows that a student has more chance passing his exam if studying hours is higher. **\n",
    "<img src=\"images/logistic.jpeg\" />\n",
    "\n",
    "** In the graph, the S-shape curve is sigmoid function, **\n",
    "\n",
    "\\begin{equation}\n",
    "p = \\frac{1}{1 + e^{-(b+wx)}}\n",
    "\\end{equation}\n",
    "\n",
    "**which is used to simulate the binary outcome 1/0 using probability of this event. We can set a cut-point to divide the probability into two class problem. For example p=0.6, which is a horizontal line, p>0.6, pass. Otherwise, fail.**\n",
    "\n",
    "** In the equation the b + wx is the linear term related to the hour spent x. The curve changes with different b + wx. **\n",
    "<img src=\"images/logistic_more.png\" width='400' height='400' />\n",
    "\n",
    "**Now we want to find the linear relation. First we can find:** \n",
    "\n",
    "\\begin{equation}\n",
    "e^{-(b+wx)} = \\frac{1-p}{p}\n",
    "\\end{equation}\n",
    "\n",
    "**Now we take natural log on both sides:**\n",
    "\n",
    "\\begin{equation}\n",
    "log(\\frac{p}{1-p}) = b + wx\n",
    "\\end{equation}\n",
    "\n",
    "** This is the logistic regression, where p/(1-p) is called odd ratio.**\n",
    "\n",
    "** If we use z = log(p/1-p), we will have a linear function again: **\n",
    "\n",
    "\\begin{equation}\n",
    "z = b + wx\n",
    "\\end{equation}\n",
    "\n",
    "**In a similar way, we can solve it as a linear regression.** \n",
    "\n",
    "  \n",
    "** Using logistic regression needs to meet some assumptions, but the residual distibution do not need to be normally distributed.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We use  the breast cancer dataset as example to test logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in breast-cancer data using sk-lean\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load data from sklearn dataset\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# we got two datasets and convert them to dataframe\n",
    "df1 = pd.DataFrame(cancer.data)\n",
    "df2 = pd.DataFrame(cancer.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "       0      1       2       3        4        5       6        7\n",
      "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710\n",
      "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017\n",
      "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790\n",
      "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520\n",
      "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430\n"
     ]
    }
   ],
   "source": [
    "# Check the data part\n",
    "print(df1.shape)\n",
    "\n",
    "# Display the first 8 columns \n",
    "print(df1.iloc[:, 0:8].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (569, 1)\n",
      "   0\n",
      "0  0\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "     0\n",
      "564  0\n",
      "565  0\n",
      "566  0\n",
      "567  0\n",
      "568  1\n"
     ]
    }
   ],
   "source": [
    "# check target part\n",
    "print(\"data shape\",df2.shape)\n",
    "print(df2.head())\n",
    "print(df2.tail())\n",
    "#df2.sum() # sum() will give how many '1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=   real= 1     predicted= 1\n",
      "i=   real= 1     predicted= 1\n",
      "i=   real= 0     predicted= 0\n",
      "i=   real= 1     predicted= 1\n",
      "i=   real= 0     predicted= 0\n"
     ]
    }
   ],
   "source": [
    "## MACHINE LEARNING: sk-learn logistic regression \n",
    "# data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target)\n",
    "                                                    \n",
    "# training model\n",
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# test model \n",
    "y_pred = model.predict(X_test) \n",
    "\n",
    "# check the first 5: real label vs. prediction \n",
    "for i in range(5):\n",
    "    print('i=', '  real=', y_test[i], '    predicted=',y_pred[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.958\n",
      "Test set score: 0.958\n"
     ]
    }
   ],
   "source": [
    "# training score (accuracy)\n",
    "print(\"Training set score: %.3f\"%model.score(X_train, y_train))\n",
    "\n",
    "# testing score (accuracy)\n",
    "print(\"Test set score: %.3f\"%model.score(X_test, y_test))\n",
    "\n",
    "# there is overfitting if Training score > test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48  5]\n",
      " [ 1 89]]\n"
     ]
    }
   ],
   "source": [
    "# check the confustion matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Code\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Accuracy score : 0.951\n",
      "[[43  4]\n",
      " [ 3 93]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target)\n",
    "                                                    \n",
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test) \n",
    "\n",
    "print(\"\\nTesting Accuracy score : %.3f\" %(accuracy_score(y_test, y_pred)))\n",
    "print(confusion_matrix(y_test, y_pred)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the accuracy and confusioon matrix, we see that logistic regresion can perform 97% accuracy. It is simple and very useful algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
